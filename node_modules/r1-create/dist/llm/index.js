"use strict";
/**
 * LLM and messaging module for R1 AI integration
 * Provides structured messaging and LLM interaction capabilities
 */
Object.defineProperty(exports, "__esModule", { value: true });
exports.llmHelpers = exports.messaging = exports.LLMHelpers = exports.R1Messaging = void 0;
/**
 * LLM and messaging API for R1 interactions
 */
class R1Messaging {
    constructor() {
        this.messageHandlers = new Set();
        this.isInitialized = false;
        this.initializeMessageHandler();
    }
    /**
     * Send a simple message to the server
     * @param message Message text
     * @param options Message options
     */
    async sendMessage(message, options = {}) {
        const payload = {
            message,
            ...options
        };
        if (typeof PluginMessageHandler !== 'undefined') {
            PluginMessageHandler.postMessage(JSON.stringify(payload));
        }
        else {
            throw new Error('PluginMessageHandler not available. Make sure you are running in R1 environment.');
        }
    }
    /**
     * Send a message and get LLM response
     * @param message Message text
     * @param options LLM options
     */
    async askLLM(message, options = {}) {
        await this.sendMessage(message, {
            useLLM: true,
            ...options
        });
    }
    /**
     * Send a SERP API request for web search
     * @param query Search query
     * @param options Additional options
     */
    async searchWeb(query, options = {}) {
        const payload = {
            message: JSON.stringify({
                query: query,
                useLocation: false,
                tag: 'search'
            }),
            useSerpAPI: true,
            ...options
        };
        if (typeof PluginMessageHandler !== 'undefined') {
            PluginMessageHandler.postMessage(JSON.stringify(payload));
        }
        else {
            throw new Error('PluginMessageHandler not available. Make sure you are running in R1 environment.');
        }
    }
    /**
     * Send text for text-to-speech output (without LLM processing)
     * @param text Text to speak
     * @param options Additional options
     */
    async speakText(text, options = {}) {
        await this.sendMessage(text, {
            useLLM: false,
            wantsR1Response: true,
            ...options
        });
    }
    /**
     * Ask LLM to speak response through R1 speaker
     * @param message Message text
     * @param saveToJournal Whether to save interaction to journal
     */
    async askLLMSpeak(message, saveToJournal = false) {
        await this.askLLM(message, {
            wantsR1Response: true,
            wantsJournalEntry: saveToJournal
        });
    }
    /**
     * Ask LLM for JSON structured response
     * @param message Message text (should specify desired JSON format)
     * @param options LLM options
     */
    async askLLMJSON(message, options = {}) {
        const jsonMessage = message.includes('JSON') ? message :
            `${message}. Please respond with a valid JSON object.`;
        await this.askLLM(jsonMessage, options);
    }
    /**
     * Add message handler for incoming responses
     * @param handler Function to handle incoming messages
     */
    onMessage(handler) {
        this.messageHandlers.add(handler);
    }
    /**
     * Remove message handler
     * @param handler Handler function to remove
     */
    offMessage(handler) {
        this.messageHandlers.delete(handler);
    }
    /**
     * Remove all message handlers
     */
    removeAllHandlers() {
        this.messageHandlers.clear();
    }
    /**
     * Close the current plugin/webview
     */
    closePlugin() {
        if (typeof closeWebView !== 'undefined') {
            closeWebView.postMessage('');
        }
    }
    initializeMessageHandler() {
        if (this.isInitialized || typeof window === 'undefined')
            return;
        // Set up global message handler
        window.onPluginMessage = (data) => {
            try {
                // Try to parse data.data as JSON if it exists
                let parsedData = undefined;
                if (data.data) {
                    try {
                        parsedData = JSON.parse(data.data);
                    }
                    catch (e) {
                        // data.data is not valid JSON, keep as string
                        parsedData = data.data;
                    }
                }
                // Call all registered handlers
                const enhancedData = { ...data, parsedData };
                this.messageHandlers.forEach(handler => {
                    try {
                        handler(enhancedData);
                    }
                    catch (error) {
                        console.error('Error in message handler:', error);
                    }
                });
            }
            catch (error) {
                console.error('Error processing plugin message:', error);
            }
        };
        this.isInitialized = true;
    }
    /**
     * Generate audio file from text-to-speech (browser only)
     * Uses Web Speech API to synthesize speech and capture as audio blob
     * @param text Text to convert to audio
     * @param options Speech synthesis options
     * @returns Promise resolving to audio blob or null if not supported
     */
    async textToSpeechAudio(text, options = {}) {
        // Only works in browser environment
        if (typeof window === 'undefined' || !window.speechSynthesis) {
            throw new Error('Text-to-speech audio generation only available in browser with Web Speech API support');
        }
        return new Promise((resolve, reject) => {
            try {
                // Create speech utterance
                const utterance = new SpeechSynthesisUtterance(text);
                // Apply options
                if (options.voice)
                    utterance.voice = options.voice;
                if (options.rate !== undefined)
                    utterance.rate = options.rate;
                if (options.pitch !== undefined)
                    utterance.pitch = options.pitch;
                if (options.volume !== undefined)
                    utterance.volume = options.volume;
                // Listen for speech end
                utterance.onend = () => {
                    // Currently, we can't capture the audio output from speech synthesis
                    // This would require advanced techniques like AudioWorklet or WebRTC
                    // For now, we just speak and return null
                    resolve(null);
                };
                utterance.onerror = (error) => {
                    reject(new Error(`Speech synthesis failed: ${error.error}`));
                };
                // Speak the text
                window.speechSynthesis.speak(utterance);
            }
            catch (error) {
                reject(error);
            }
        });
    }
}
exports.R1Messaging = R1Messaging;
/**
 * Convenient helper functions for common LLM interactions
 */
class LLMHelpers {
    constructor(messaging) {
        this.messaging = messaging;
    }
    /**
     * Ask LLM about user memories/context
     */
    async getUserMemories() {
        await this.messaging.askLLMJSON("Tell me what you know about me. Return only a JSON message formatted as {'facts': ['fact1', 'fact2', ...]}");
    }
    /**
     * Ask LLM to analyze an image or data
     * @param prompt Analysis prompt
     * @param data Optional data to analyze
     */
    async analyzeData(prompt, data) {
        let message = prompt;
        if (data) {
            message += ` Data: ${JSON.stringify(data)}`;
        }
        message += ' Please respond with a JSON analysis.';
        await this.messaging.askLLMJSON(message);
    }
    /**
     * Ask LLM to perform a task and speak the result
     * @param task Task description
     * @param saveToJournal Whether to save to journal
     */
    async performTask(task, saveToJournal = true) {
        await this.messaging.askLLMSpeak(task, saveToJournal);
    }
    /**
     * Convert text to speech using R1 speaker (no LLM processing)
     * @param text Text to speak
     * @param saveToJournal Whether to save to journal
     */
    async textToSpeech(text, saveToJournal = false) {
        await this.messaging.speakText(text, { wantsJournalEntry: saveToJournal });
    }
    /**
     * Get LLM suggestions for user interface
     * @param context Current UI context
     */
    async getUISuggestions(context) {
        await this.messaging.askLLMJSON(`Given this UI context: "${context}", provide suggestions for user actions. ` +
            `Respond with JSON format: {"suggestions": [{"action": "action_name", "description": "description"}]}`);
    }
    /**
     * Generate audio file from text-to-speech (browser only)
     * @param text Text to convert to audio
     * @param options Speech synthesis options
     */
    async textToSpeechAudio(text, options = {}) {
        return this.messaging.textToSpeechAudio(text, options);
    }
}
exports.LLMHelpers = LLMHelpers;
// Export singleton instances
exports.messaging = new R1Messaging();
exports.llmHelpers = new LLMHelpers(exports.messaging);
//# sourceMappingURL=index.js.map